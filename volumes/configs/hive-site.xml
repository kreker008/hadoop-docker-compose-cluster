<configuration>
	<property>
		<name>javax.jdo.option.ConnectionURL</name>
		<value>jdbc:postgresql://hivemetastore:5432/hivemetastore?createDatabaseIfNotExist=true</value>
		<description>JDBC connect string for a JDBC metastore</description>
	</property>
	<property>
		<name>javax.jdo.option.ConnectionDriverName</name>
		<value>org.postgresql.Driver</value>
		<description>Driver class name for a JDBC metastore</description>
	</property>
	<property>
		<name>javax.jdo.option.ConnectionUserName</name>
		<value>$HIVEMETASTORE_DB_USERNAME</value>
		<description>Username to use against metastore database</description>
	</property>
	<property>
		<name>javax.jdo.option.ConnectionPassword</name>
		<value>$HIVEMETASTORE_DB_PASS</value>
		<description>Password to use against metastore database</description>
	</property>
	<property>
		<name>datanucleus.autoCreateSchema</name>
		<value>true</value>
	</property>
	<property>
		<name>datanucleus.fixedDatastore</name>
		<value>true</value>
	</property>
	<property>
		<name>datanucleus.autoCreateTables</name>
		<value>true</value>
	</property>
	<property>
		<name>hive.server2.enable.doAs</name>
		<value>false</value>
	</property>
	<property>
		<name>hive.execution.engine</name>
		<value>spark</value>
	</property>
	<property>
		<name>spark.master</name>
		<value>spark://namenode:7077</value>
	</property>
	<property>
		<name>spark.yarn.jars</name>
		<value>hdfs://namenode:${NAMENODE_RPC_PORT}/spark-jars/jars/*</value>
	</property>
	<property>
		<name>hive.metastore.warehouse.dir</name>
		<value>/apps/hive/warehouse</value>
	</property>
</configuration>